{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d61b543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß DIAGNOSI TENSORFLOW E GPU\n",
      "============================================================\n",
      "\n",
      "üìã INFORMAZIONI SISTEMA:\n",
      "Python version: 3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]\n",
      "TensorFlow version: 2.19.0\n",
      "\n",
      "üî® BUILD TENSORFLOW:\n",
      "Built with CUDA: False\n",
      "Built with GPU support: False\n",
      "\n",
      "üéÆ INFORMAZIONI GPU/CUDA:\n",
      "‚úÖ nvidia-smi funziona (driver NVIDIA installato)\n",
      "üéÆ GPU rilevata: |   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "‚úÖ CUDA Toolkit: Cuda compilation tools, release 11.8, V11.8.89\n",
      "\n",
      "üîß DISPOSITIVI TENSORFLOW:\n",
      "Tutti i dispositivi fisici:\n",
      "  - PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "\n",
      "Dispositivi GPU specifici:\n",
      "‚ùå Nessuna GPU rilevata da TensorFlow\n",
      "\n",
      "üß™ TEST CALCOLO:\n",
      "‚ö†Ô∏è GPU non disponibile, test su CPU...\n",
      "Calcolo CPU completato: \n",
      "[[1. 3.]\n",
      " [3. 7.]]\n",
      "\n",
      "============================================================\n",
      "‚úÖ nvidia-smi funziona (driver NVIDIA installato)\n",
      "üéÆ GPU rilevata: |   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "‚úÖ CUDA Toolkit: Cuda compilation tools, release 11.8, V11.8.89\n",
      "\n",
      "üîß DISPOSITIVI TENSORFLOW:\n",
      "Tutti i dispositivi fisici:\n",
      "  - PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "\n",
      "Dispositivi GPU specifici:\n",
      "‚ùå Nessuna GPU rilevata da TensorFlow\n",
      "\n",
      "üß™ TEST CALCOLO:\n",
      "‚ö†Ô∏è GPU non disponibile, test su CPU...\n",
      "Calcolo CPU completato: \n",
      "[[1. 3.]\n",
      " [3. 7.]]\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üîç DIAGNOSTICA COMPLETA TENSORFLOW + GPU\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß DIAGNOSI TENSORFLOW E GPU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Informazioni sistema\n",
    "print(\"\\nüìã INFORMAZIONI SISTEMA:\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# 2. Verifica build TensorFlow\n",
    "print(\"\\nüî® BUILD TENSORFLOW:\")\n",
    "print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"Built with GPU support: {tf.test.is_built_with_gpu_support()}\")\n",
    "\n",
    "# 3. Driver NVIDIA e CUDA\n",
    "print(\"\\nüéÆ INFORMAZIONI GPU/CUDA:\")\n",
    "try:\n",
    "    import subprocess\n",
    "    # Verifica driver NVIDIA\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ nvidia-smi funziona (driver NVIDIA installato)\")\n",
    "        # Estrai info GPU dalla prima riga con GPU\n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'NVIDIA' in line and ('RTX' in line or 'GTX' in line or 'Tesla' in line):\n",
    "                print(f\"üéÆ GPU rilevata: {line.strip()}\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"‚ùå nvidia-smi non funziona (problema driver NVIDIA)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nel verificare nvidia-smi: {e}\")\n",
    "\n",
    "# Verifica CUDA Toolkit\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        for line in result.stdout.split('\\n'):\n",
    "            if 'release' in line:\n",
    "                print(f\"‚úÖ CUDA Toolkit: {line.strip()}\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"‚ùå nvcc non trovato (CUDA Toolkit non installato o non nel PATH)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nel verificare nvcc: {e}\")\n",
    "\n",
    "# 4. Dispositivi TensorFlow\n",
    "print(\"\\nüîß DISPOSITIVI TENSORFLOW:\")\n",
    "print(\"Tutti i dispositivi fisici:\")\n",
    "all_devices = tf.config.list_physical_devices()\n",
    "for device in all_devices:\n",
    "    print(f\"  - {device}\")\n",
    "\n",
    "print(\"\\nDispositivi GPU specifici:\")\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"‚úÖ {len(gpu_devices)} GPU trovate:\")\n",
    "    for i, gpu in enumerate(gpu_devices):\n",
    "        print(f\"  - GPU {i}: {gpu}\")\n",
    "        # Ottieni dettagli GPU\n",
    "        try:\n",
    "            details = tf.config.experimental.get_device_details(gpu)\n",
    "            print(f\"    Dettagli: {details}\")\n",
    "        except:\n",
    "            print(\"    (dettagli non disponibili)\")\n",
    "else:\n",
    "    print(\"‚ùå Nessuna GPU rilevata da TensorFlow\")\n",
    "\n",
    "# 5. Test di calcolo\n",
    "print(\"\\nüß™ TEST CALCOLO:\")\n",
    "if gpu_devices:\n",
    "    try:\n",
    "        print(\"Tentativo calcolo su GPU...\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "            b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "            print(\"‚úÖ Calcolo GPU riuscito!\")\n",
    "            print(f\"Risultato: \\n{c.numpy()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore calcolo GPU: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU non disponibile, test su CPU...\")\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(f\"Calcolo CPU completato: \\n{c.numpy()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf591d9",
   "metadata": {},
   "source": [
    "# ü©∫ Diagnosi Problemi GPU Comuni\n",
    "\n",
    "## ‚ùå Se TensorFlow non trova la GPU, controlla:\n",
    "\n",
    "### 1. **Driver NVIDIA**\n",
    "- Installa/aggiorna driver NVIDIA pi√π recenti\n",
    "- Verifica con `nvidia-smi` nel terminale\n",
    "- Riavvia dopo installazione driver\n",
    "\n",
    "### 2. **CUDA Toolkit 11.8**\n",
    "- Scarica da: https://developer.nvidia.com/cuda-11-8-0-download-archive\n",
    "- Installa con opzioni **Custom (Advanced)**\n",
    "- Verifica con `nvcc --version`\n",
    "- Aggiungi al PATH: `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin`\n",
    "\n",
    "### 3. **cuDNN 8.6**\n",
    "- Scarica da: https://developer.nvidia.com/cudnn (richiede account gratuito)\n",
    "- Estrai e copia file in cartelle CUDA\n",
    "- Riavvia il computer dopo installazione\n",
    "\n",
    "### 4. **TensorFlow**\n",
    "- Reinstalla TensorFlow: `pip uninstall tensorflow && pip install tensorflow>=2.13.0`\n",
    "- Verifica versione compatibile CUDA/cuDNN\n",
    "\n",
    "### 5. **Variabili d'Ambiente**\n",
    "```\n",
    "CUDA_PATH = C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\n",
    "PATH += C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\n",
    "```\n",
    "\n",
    "## ‚úÖ Test Rapidi\n",
    "- `nvidia-smi` ‚Üí deve mostrare la GPU\n",
    "- `nvcc --version` ‚Üí deve mostrare CUDA 11.8\n",
    "- Riavvia VS Code/Jupyter dopo installazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e2eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICA VARIABILI D'AMBIENTE CUDA:\n",
      "==================================================\n",
      "‚úÖ CUDA_PATH: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\n",
      "‚úÖ CUDA_PATH_V11_8: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\n",
      "‚ùå CUDNN_PATH: NON IMPOSTATA\n",
      "\n",
      "PATH:\n",
      "  ‚úÖ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\n",
      "  ‚úÖ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\libnvvp\n",
      "  ‚úÖ C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR\n",
      "  ‚úÖ C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common\n",
      "  ‚úÖ C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2022.3.0\\\n",
      "\n",
      "üîç VERIFICA FILE CHIAVE:\n",
      "‚úÖ CUDA Compiler: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\nvcc.exe\n",
      "‚úÖ CUDA BLAS: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\cublas64_11.dll\n",
      "‚úÖ CUDA Runtime: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\cudart64_110.dll\n",
      "‚ùå cuDNN Library: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\cudnn64_8.dll\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# üîß VERIFICA VARIABILI D'AMBIENTE\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"üîç VERIFICA VARIABILI D'AMBIENTE CUDA:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variabili d'ambiente importanti\n",
    "env_vars = [\n",
    "    'CUDA_PATH',\n",
    "    'CUDA_PATH_V11_8', \n",
    "    'CUDNN_PATH',\n",
    "    'PATH'\n",
    "]\n",
    "\n",
    "for var in env_vars:\n",
    "    value = os.environ.get(var, 'NON IMPOSTATA')\n",
    "    if var == 'PATH':\n",
    "        print(f\"\\n{var}:\")\n",
    "        # Mostra solo parti rilevanti del PATH\n",
    "        paths = value.split(';') if value != 'NON IMPOSTATA' else []\n",
    "        cuda_paths = [p for p in paths if 'CUDA' in p.upper() or 'NVIDIA' in p.upper()]\n",
    "        if cuda_paths:\n",
    "            for path in cuda_paths:\n",
    "                print(f\"  ‚úÖ {path}\")\n",
    "        else:\n",
    "            print(\"  ‚ùå Nessun path CUDA/NVIDIA trovato nel PATH\")\n",
    "    else:\n",
    "        status = \"‚úÖ\" if value != 'NON IMPOSTATA' else \"‚ùå\"\n",
    "        print(f\"{status} {var}: {value}\")\n",
    "\n",
    "# Verifica esistenza file chiave\n",
    "print(f\"\\nüîç VERIFICA FILE CHIAVE:\")\n",
    "cuda_base = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\"\n",
    "key_files = [\n",
    "    (f\"{cuda_base}\\\\bin\\\\nvcc.exe\", \"CUDA Compiler\"),\n",
    "    (f\"{cuda_base}\\\\bin\\\\cublas64_11.dll\", \"CUDA BLAS\"),\n",
    "    (f\"{cuda_base}\\\\bin\\\\cudart64_110.dll\", \"CUDA Runtime\"),\n",
    "    (f\"{cuda_base}\\\\bin\\\\cudnn64_8.dll\", \"cuDNN Library\")\n",
    "]\n",
    "\n",
    "for file_path, description in key_files:\n",
    "    exists = os.path.exists(file_path)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"{status} {description}: {file_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce928180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç DIAGNOSI COMPATIBILIT√Ä TENSORFLOW-CUDA\n",
    "\n",
    "print(\"üîß ANALISI COMPATIBILIT√Ä TENSORFLOW-CUDA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Verifica versioni specifiche\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# 2. Controlla build info dettagliata\n",
    "build_info = tf.sysconfig.get_build_info()\n",
    "print(f\"\\nüìã BUILD INFO TENSORFLOW:\")\n",
    "for key, value in build_info.items():\n",
    "    if 'cuda' in key.lower() or 'cudnn' in key.lower():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# 3. Verifica librerie CUDA caricate\n",
    "print(f\"\\nüîó LIBRERIE CUDA/CUDNN:\")\n",
    "print(f\"CUDA built: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"GPU support: {tf.test.is_built_with_gpu_support()}\")\n",
    "\n",
    "# 4. Test caricamento librerie specifiche\n",
    "import ctypes.util\n",
    "import os\n",
    "\n",
    "print(f\"\\nüîç RICERCA LIBRERIE DINAMICHE:\")\n",
    "\n",
    "# Lista librerie critiche\n",
    "critical_libs = [\n",
    "    \"cudart64_110.dll\",  # CUDA Runtime\n",
    "    \"cublas64_11.dll\",   # CUDA BLAS\n",
    "    \"cudnn64_8.dll\",     # cuDNN\n",
    "    \"cufft64_10.dll\",    # CUDA FFT\n",
    "    \"curand64_10.dll\"    # CUDA Random\n",
    "]\n",
    "\n",
    "for lib in critical_libs:\n",
    "    # Cerca nel PATH di sistema\n",
    "    found = ctypes.util.find_library(lib.replace('.dll', ''))\n",
    "    if found:\n",
    "        print(f\"  ‚úÖ {lib}: trovata\")\n",
    "    else:\n",
    "        # Cerca manualmente in directory CUDA\n",
    "        cuda_paths = [\n",
    "            r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\",\n",
    "            r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7\\bin\",\n",
    "            r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\bin\"\n",
    "        ]\n",
    "        found_manual = False\n",
    "        for path in cuda_paths:\n",
    "            full_path = os.path.join(path, lib)\n",
    "            if os.path.exists(full_path):\n",
    "                print(f\"  ‚ö†Ô∏è  {lib}: trovata in {path} (ma non nel PATH)\")\n",
    "                found_manual = True\n",
    "                break\n",
    "        if not found_manual:\n",
    "            print(f\"  ‚ùå {lib}: NON TROVATA\")\n",
    "\n",
    "# 5. Verifica compatibilit√† versioni\n",
    "print(f\"\\nüéØ DIAGNOSI COMPATIBILIT√Ä:\")\n",
    "tf_version = tf.__version__\n",
    "\n",
    "# Matrice compatibilit√† TensorFlow-CUDA\n",
    "compatibility = {\n",
    "    \"2.13.0\": {\"cuda\": \"11.8\", \"cudnn\": \"8.6\"},\n",
    "    \"2.12.0\": {\"cuda\": \"11.8\", \"cudnn\": \"8.6\"},\n",
    "    \"2.11.0\": {\"cuda\": \"11.2\", \"cudnn\": \"8.1\"},\n",
    "    \"2.10.0\": {\"cuda\": \"11.2\", \"cudnn\": \"8.1\"}\n",
    "}\n",
    "\n",
    "for tf_ver, reqs in compatibility.items():\n",
    "    if tf_version.startswith(tf_ver[:4]):  # Match major.minor\n",
    "        print(f\"‚úÖ TensorFlow {tf_version} richiede:\")\n",
    "        print(f\"   CUDA: {reqs['cuda']}\")\n",
    "        print(f\"   cuDNN: {reqs['cudnn']}\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Versione TensorFlow {tf_version} non in matrice compatibilit√†\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba441e",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è SOLUZIONI per GPU Rilevata ma Non Usata da TensorFlow\n",
    "\n",
    "## ‚ùó **Problema Identificato**: GPU rilevata da sistema ma NON da TensorFlow\n",
    "\n",
    "Questo indica un **problema di compatibilit√† CUDA/cuDNN** con la versione TensorFlow.\n",
    "\n",
    "## üîß Soluzioni Ordinate per Priorit√†:\n",
    "\n",
    "### 1. **Reinstallazione TensorFlow Completa** (RACCOMANDATO)\n",
    "```bash\n",
    "# Disinstalla completamente TensorFlow\n",
    "pip uninstall tensorflow tensorflow-gpu tensorflow-cpu\n",
    "\n",
    "# Reinstalla versione stabile con GPU\n",
    "pip install tensorflow[and-cuda]==2.13.0\n",
    "```\n",
    "\n",
    "### 2. **Verifica Versioni CUDA/cuDNN Compatibili**\n",
    "- **TensorFlow 2.13+**: Richiede CUDA 11.8 + cuDNN 8.6\n",
    "- **TensorFlow 2.12**: Richiede CUDA 11.8 + cuDNN 8.6  \n",
    "- **TensorFlow 2.11**: Richiede CUDA 11.2 + cuDNN 8.1\n",
    "\n",
    "### 3. **Installazione CUDA/cuDNN Corretta**\n",
    "```bash\n",
    "# Se hai CUDA sbagliata, disinstalla e reinstalla\n",
    "# CUDA 11.8: https://developer.nvidia.com/cuda-11-8-0-download-archive\n",
    "# cuDNN 8.6: https://developer.nvidia.com/cudnn (account richiesto)\n",
    "```\n",
    "\n",
    "### 4. **Forza Rilevamento GPU** (Test)\n",
    "```python\n",
    "# Aggiungi questo all'inizio dei notebook\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "import tensorflow as tf\n",
    "# Forza crescita memoria GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "```\n",
    "\n",
    "### 5. **Installazione con Conda** (Alternativa)\n",
    "```bash\n",
    "# Se pip non funziona, prova conda\n",
    "conda install tensorflow-gpu=2.13.0\n",
    "```\n",
    "\n",
    "## ‚ö° **Test Immediato**\n",
    "Dopo ogni tentativo, riavvia VS Code e testa con:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "print(\"GPU disponibili:\", len(tf.config.list_physical_devices('GPU')))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
